# AWS alb의 fail-open에 대하여

AWS의 alb는 특이한 작동방식이 있습니다.  
AWS 프리티어를 통해서 샘플 인프라를 생성해보신 분들은 경험해보셨을 수 도 있습니다. 바로 `fail open`입니다.  
`fail-open`은 쉽게 말해 모든 경로의 `health`체크가 실패하면, 모든 경로를 열겠다는 말입니다.  
기본적으로 AWS의 alb는 헬스체크를 통해서 타겟 서버의 상태를 체크합니다. 타겟 서버가 요청한 내용에 대해서 어떤 응답을 하는가는 관계가 없습니다.  
타겟에 대해 헬스체크 신호를 보내고 그 신호에 적절한 응답이 없을 경우만 타겟을 타겟그룹에서 제외(정확히는 요청을 보낼 타겟 목록에서 제외)하게 됩니다.  
만약 ALB 타겟 그룹에 있는 모든 타겟들의 상태가 전부 `unhealthy`라면 어떨까요? 그런 경우, ALB의 작동을 멈출까요? 만약 그렇게 될 경우, 서비스 자체가 마비되어 버립니다.  
AWS는 다음과 같은 상황에서 alb가 모든 타겟에 경로를 열어버립니다. 말 그대로 모든 타겟에 그냥 신호를 보냅니다. 타겟의 상태와 상관 없이 보내기 때문에, 타겟이 `unhealthy`상태여도 서비스는 유지되게 됩니다.  
 프리티어로 작업 하셨을때도 경험 한 경우가 있을거라고 생각이 됩니다. 타겟이 하나인 ALB에서 타겟의 상태가 `unhealthy`여도 신호가 계속 가고, 서비스가 유지되는 경우가 있습니다.
 AWS의 alb의 다음과 같은 특성으로 인해서 작동된다고 보시면 됩니다.  

## OCI와 AWS alb의 차이점

![normal_architecture](https://github.com/cotes2020/jekyll-theme-chirpy/assets/74250270/5dc916da-610c-46ce-8384-0b4d43c77d75)  
다음과 같이 한 로드밸런서에 두개의 인스턴스가 붙어있는 상태를 가정하겠습니다. 이 상황에서 만약 한 인스턴스의 WAS가 모종의 이유로 (오류나 배포)인해서 내려가게 되는데  
  
![issue](https://github.com/cotes2020/jekyll-theme-chirpy/assets/74250270/cde34330-e806-4fc6-a0fe-fef684b18e67)  
7레이어에 해당하는 보통의 ALB들은 `Health Check`를 하기 직전까지 이런 WAS의 이슈를 알지 못합니다. 인스턴스 자체는 통신이 잘 되고 있기 때문이죠. 그래서 이런 이슈가 존재하는 상태로 새로고침을 계속하면, 503과 정상페이지가 번갈아 나오는 것을 확인할 수 있습니다.  

![AWS](https://github.com/cotes2020/jekyll-theme-chirpy/assets/74250270/36d947c0-4411-4bbe-8c85-7a1187425cdc)  
위와 같이 `Health Check`전까지는 계속해서 이슈 페이지가 뜹니다. 이건 네이버 클라우드도 이런식이고, 이 문제 때문에 배포할 때에도, 추가적인 작업을 필요로 합니다.  
  
OCI는 조금 다릅니다. OCI의 로드밸런서는 리버스 프록시까지 겸합니다.  
![OCI](https://github.com/cotes2020/jekyll-theme-chirpy/assets/74250270/18e357b3-4d41-4fc7-90a4-b94fa61da766)  
그래서 인스턴스 응답에 따라서 아예 다른 인스턴스로 임의로 보내기도 합니다. 헬스체크의 시간과 관계없이 작동합니다. 다음과 같은 동작을 하면서 인스턴스를 타겟그룹에서 빼는지는 확인해보지 못했지만(OCI의 계정생성이 그다지 유연하지 못합니다.) AWS와 이런 동작 방식의 차이를 이해하고 있어야, 배포와 같은 이벤트에서 문제 없이 넘어갈 수 있겠습니다.  
